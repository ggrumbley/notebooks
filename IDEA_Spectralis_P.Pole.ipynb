{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectralis P.Pole Thickness Map\n",
    "v1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Add File Paths Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Participants file that ends with `.mer`\n",
    "participants  = '/Users/gary/Desktop/GaryPPole/20160815RCPts.mer'\n",
    "\n",
    "# Quality Control File\n",
    "quality_control = '/Users/gary/Desktop/GaryPPole/FMPQC22Aug2016.mer'\n",
    "\n",
    "# Folder full o' .mer files exported from FM\n",
    "folder = '/Users/gary/Desktop/GaryPPole/20160823OHTS_SpectralisThickMap/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Segment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def segment(folder, qc, participants):\n",
    "    rnfl_timey = ''\n",
    "    ipl_timey = ''\n",
    "    gcl_timey = ''\n",
    "    # Create Empty DataFrame for failed QC Links\n",
    "    df_unlinked = pd.DataFrame()\n",
    "    \n",
    "    #Create empty OHTS DataFrames\n",
    "    ohts_ipl_df = pd.DataFrame()\n",
    "    ohts_gcl_df = pd.DataFrame()\n",
    "    ohts_rnfl_df = pd.DataFrame()\n",
    "    \n",
    "    # Create Participants DataFrame\n",
    "    pts = pd.read_csv(participants)\n",
    "    pts['rc_researchid'] = pts['rc_researchid'].astype(str)     \n",
    "    pts['rc_researchid'] = pts['rc_researchid'].str.upper()\n",
    "    ohts_ids = pts[pts.rc_ohts_id.notnull()]\n",
    "    pts['rc_ohts_id'] = pts['rc_ohts_id'].astype(str)       \n",
    "    pts['rc_ohts_id'] = pts['rc_ohts_id'].str.zfill(5)\n",
    "    pts['rc_researchid'] = pts['rc_researchid'].str.zfill(5) \n",
    "    \n",
    "    \n",
    "    #Import and format QC file\n",
    "    qc = pd.read_csv(qc, parse_dates=True, dayfirst=True, low_memory=False)\n",
    "    qc['ExamDate'] = qc['ExamDate'].astype(str)\n",
    "    qc.rename(columns={'ID': 'PatientID'}, inplace=True)\n",
    "    qc['PatientID'] = qc['PatientID'].astype(str).str.zfill(5)\n",
    "\n",
    "    # Create 2016 list\n",
    "    year_2016 = qc[['PatientID', 'ExamDate']].where(qc['ExamDate'].str.slice(-2) == '16')\n",
    "    for fi in glob.iglob(folder + '*.txt'):\n",
    "        df = pd.read_csv(fi, sep='\\t', encoding='iso-8859-1', low_memory=False)\n",
    "        df['PatientID'] = df['PatientID'].astype(str)\n",
    "        df['PatientID'] = df['PatientID'].str.zfill(5)\n",
    "        df['PatientID'] = df['PatientID'].str.upper()\n",
    "        df['ExamDate'] = df['ExamDate'].astype(str)\n",
    "        year_2016 = year_2016.append(df[['PatientID', 'ExamDate']].where(df['ExamDate'].str.slice(-2) == '16'))      \n",
    "    year_2016 = year_2016[year_2016['PatientID'].notnull()]\n",
    "    year_2016 = year_2016.drop_duplicates()\n",
    "    \n",
    "    # Process Output Files\n",
    "    for fi in glob.iglob(folder + '*.txt'):\n",
    "        # Current Data File\n",
    "        df = pd.read_csv(fi, sep='\\t', encoding='iso-8859-1', low_memory=False)\n",
    "        \n",
    "        # Create file pieces\n",
    "        file_parts = os.path.basename(fi).split('_')\n",
    "        input_file = os.path.basename(fi).upper()\n",
    "        path = os.path.dirname(fi)\n",
    "        timey = file_parts[0]\n",
    "        namey = ''\n",
    "        save_path = path + '/' + 'PPOLE_OUTPUT/'\n",
    "        \n",
    "        # Create Sub-Directory if one does not yet exist\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        if 'IPL' in input_file:\n",
    "            fi_type = 'IPL'\n",
    "        elif 'GCL' in input_file:\n",
    "            fi_type = 'GCL'\n",
    "        elif 'RNFL' in input_file:\n",
    "            fi_type = 'RNFL'\n",
    "        \n",
    "        # CASE FIX\n",
    "        df['Lastname'] = df['Lastname'].astype(str)\n",
    "        df['Lastname'] = df['Lastname'].str.zfill(5)\n",
    "        df['Lastname'] = df['Lastname'].str.upper()\n",
    "        df['PatientID'] = df['PatientID'].astype(str)\n",
    "        df['PatientID'] = df['PatientID'].str.zfill(5)\n",
    "        df['PatientID'] = df['PatientID'].str.upper()\n",
    "        df['ExamDate'] = df['ExamDate'].astype(str)\n",
    "        df['ExamMonth'] = df['ExamDate'].str.split('/').str[0].str.zfill(2)\n",
    "        df['ExamDay'] = df['ExamDate'].str.split('/').str[1].str.zfill(2)\n",
    "        df['ExamYear'] = df['ExamDate'].str.split('/').str[2].str.zfill(4)\n",
    "        df['ExamDate'] = df['ExamMonth'].map(str) + '/' + df['ExamDay'].map(str) + '/' + df['ExamYear'].map(str)\n",
    "\n",
    "        df['Lastname'] = df['Lastname'].str.upper()\n",
    "        df['PatientID'] = df['PatientID'].str.upper()\n",
    "        \n",
    "             # Parse year\n",
    "        df['2016 OHTS visit'] = np.where(df['PatientID'].isin(year_2016['PatientID']), 'Yes', 'No')\n",
    "\n",
    "        df_all = pd.merge(df, \\\n",
    "                            qc[['ExamDate', 'ExamTimeRAW', \\\n",
    "                                'ExaminedStruct', 'NumBScans', 'OCTHIRES', 'QCExt1CorrectScanType', \\\n",
    "                                'QCQualityScore', 'QCSignalStrength', 'ArtMeanImages', 'QCOCTArtImageMode', \\\n",
    "                                'QCScanPatternCentered', 'QCScanClipped', 'QCSegAlgFail', 'QCFloaters', \\\n",
    "                                'QCArtifacts', 'QCIllumination', 'QCPossiblePathology', 'QCScanComplete', \\\n",
    "                                'QCSettings', 'QCDataAvailable', 'QCImageUsable']], \\\n",
    "                            how='left', \\\n",
    "                            left_on=['ExamDate', 'ExamTime'], \\\n",
    "                            right_on=['ExamDate', 'ExamTimeRAW'])\n",
    "        df_all.drop(['ExamTimeRAW', 'ExamMonth', 'ExamDay', 'ExamYear'], axis=1, inplace=True)\n",
    "        \n",
    "        cols = list(df_all.columns.values)\n",
    "        cols.pop(cols.index('2016 OHTS visit'))\n",
    "        df_all = df_all[cols+['2016 OHTS visit']]\n",
    "        # Add unlinked QC files to Unlinked DataFrame\n",
    "        df_noqc = df_all[df_all.ExaminedStruct.isnull()]\n",
    "        \n",
    "        if df_unlinked.empty:\n",
    "            df_unlinked = df_noqc\n",
    "        else:\n",
    "            df_unlinked = df_unlinked.append(df_noqc)\n",
    "        \n",
    "   \n",
    "        \n",
    "        # Clean FIRST_NAME Types\n",
    "        vals = {'SD': 'S1', 'NY': 'M1'}\n",
    "        df_all.replace({'Firstname': vals}, inplace=True)\n",
    "        \n",
    "        if 'OHTS' in input_file:\n",
    "            if fi_type == 'IPL':\n",
    "                ipl_timey = timey\n",
    "                \n",
    "                if ohts_ipl_df.empty:\n",
    "                    ohts_ipl_df = df_all\n",
    "                else:\n",
    "                    ohts_ipl_df = ohts_ipl_df.append(df_all)\n",
    "            elif fi_type == 'GCL':\n",
    "                gcl_timey = timey\n",
    "                \n",
    "                if ohts_gcl_df.empty:\n",
    "                    ohts_gcl_df = df_all\n",
    "                else:\n",
    "                    ohts_gcl_df = ohts_gcl_df.append(df_all)\n",
    "            elif fi_type == 'RNFL':\n",
    "                rnfl_timey = timey\n",
    "                \n",
    "                if ohts_rnfl_df.empty:\n",
    "                    ohts_rnfl_df = df_all\n",
    "                else:\n",
    "                    ohts_rnfl_df = ohts_rnfl_df.append(df_all)\n",
    "            else:\n",
    "                print(\"Not a supported file type: \" + input_file)\n",
    "        \n",
    "            \n",
    "        # If Shiley Scan create Output Files\n",
    "        elif 'DSPEC' in input_file:\n",
    "            \n",
    "            #Create list of OHTS IDs\n",
    "            ohts = df_all[df_all['Lastname'].isin(ohts_ids.rc_researchid)]\n",
    "            ohts = pd.merge(ohts, ohts_ids, left_on='Lastname', right_on='rc_researchid')\n",
    "            ohts['Lastname'] = ohts['Lastname'].astype(str)\n",
    "            ohts['PatientID'] = ohts['PatientID'].astype(str)\n",
    "            ohts['Lastname'] = ohts['rc_ohts_id']\n",
    "            ohts['PatientID'] = ohts['rc_ohts_id']\n",
    "            # Drop join columns from Participants Table\n",
    "            ohts.drop(ohts.columns[[-1, -2, -3]], axis=1, inplace=True)\n",
    "            \n",
    "            # Extract OHTS Participants\n",
    "            if fi_type == 'IPL':\n",
    "                if ohts_ipl_df.empty:\n",
    "                    ohts_ipl_df = ohts\n",
    "                else:\n",
    "                    ohts_ipl_df = ohts_ipl_df.append(ohts)\n",
    "            elif fi_type == 'GCL':\n",
    "                if ohts_gcl_df.empty:\n",
    "                    ohts_gcl_df = ohts\n",
    "                else:\n",
    "                    ohts_gcl_df = ohts_gcl_df.append(df_all)\n",
    "            elif fi_type == 'RNFL':\n",
    "                if ohts_rnfl_df.empty:\n",
    "                    ohts_rnfl_df = ohts\n",
    "                else:\n",
    "                    ohts_rnfl_df = ohts_rnfl_df.append(df_all)\n",
    "            else:\n",
    "                print(\"Not a supported file type: \" + input_file)\n",
    "                \n",
    "            # Save HGC Files\n",
    "            segey = timey + '_HGC_Spectralis_ThMap' + fi_type\n",
    "            df_all.to_csv(save_path + '/' + segey + '_ALL.csv', index=False)\n",
    "            print(segey + '_ALL.csv' + ' Created')\n",
    "            \n",
    "            # Create File of Usable Scans\n",
    "            df_usable = df_all[df_all.QCImageUsable == 'Yes']\n",
    "            df_usable.to_csv(save_path + '/' + segey + '_USABLE.csv', index=False)\n",
    "            print(segey + '_USABLE.csv' + ' Created')\n",
    "\n",
    "   \n",
    "    # Save all 3 OHTS DataFrames\n",
    "    if not ohts_ipl_df.empty:\n",
    "        ohts_ipl_df.to_csv(save_path + '/' + timey + '_OHTS_Spectralis_ThMapIPL_ALL.csv', index=False)\n",
    "        \n",
    "        # Create Usable CSV\n",
    "        ohts_ipl_usable = ohts_ipl_df[ohts_ipl_df.QCImageUsable == 'Yes']\n",
    "        ohts_ipl_usable.to_csv(save_path + '/' + timey + '_OHTS_Spectralis_ThMapIPL_USABLE.csv', index=False)\n",
    "        \n",
    "        print('OHTS IPL USABLE & ALL files created.')\n",
    "        \n",
    "    if not ohts_gcl_df.empty:\n",
    "        ohts_gcl_df.to_csv(save_path + '/' + timey + '_OHTS_Spectralis_ThMapGCL_ALL.csv', index=False)\n",
    "        \n",
    "        # Create Usable CSV\n",
    "        ohts_gcl_usable = ohts_gcl_df[ohts_gcl_df.QCImageUsable == 'Yes']\n",
    "        ohts_gcl_usable.to_csv(save_path + '/' + timey + '_OHTS_Spectralis_ThMapGCL_USABLE.csv', index=False)                          \n",
    " \n",
    "        print('OHTS GCL USABLE & ALL files created.')\n",
    "            \n",
    "    if not ohts_rnfl_df.empty:\n",
    "        ohts_rnfl_df.to_csv(save_path + '/' + timey + '_OHTS_Spectralis_ThMapRNFL_ALL.csv', index=False)\n",
    "\n",
    "        # Create Usable CSV\n",
    "        ohts_rnfl_usable = ohts_rnfl_df[ohts_rnfl_df.QCImageUsable == 'Yes']\n",
    "        ohts_rnfl_usable.to_csv(save_path + '/' + timey + '_OHTS_Spectralis_ThMapRNFL_USABLE.csv', index=False)                          \n",
    " \n",
    "        print('OHTS RNFL USABLE & ALL files created.')\n",
    "                       \n",
    "    # Save Usable Scans from OHTS DataFrames\n",
    "    \n",
    "    if df_unlinked.shape != (0, 47):\n",
    "        df_unlinked.to_csv(save_path + '/ThMapNOTlinkedtoQC.csv', index=False)\n",
    "        print('ThMapNOTlinkedtoQC.csv Created')\n",
    "    else:\n",
    "        print('All files linked to QC! \\'No ThMapNOTlinkedtoQC.csv\\' created.')\n",
    "            \n",
    "    print('-------------------------------------')\n",
    "    print('| OMG y\\'all, your files are ready!  |')\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20160822_HGC_Spectralis_ThMapRNFL_ALL.csv Created\n",
      "20160822_HGC_Spectralis_ThMapRNFL_USABLE.csv Created\n",
      "20160823_HGC_Spectralis_ThMapGCL_ALL.csv Created\n",
      "20160823_HGC_Spectralis_ThMapGCL_USABLE.csv Created\n",
      "20160823_HGC_Spectralis_ThMapIPL_ALL.csv Created\n",
      "20160823_HGC_Spectralis_ThMapIPL_USABLE.csv Created\n",
      "OHTS IPL USABLE & ALL files created.\n",
      "OHTS GCL USABLE & ALL files created.\n",
      "OHTS RNFL USABLE & ALL files created.\n",
      "ThMapNOTlinkedtoQC.csv Created\n",
      "-------------------------------------\n",
      "| OMG y'all, your files are ready!  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the segment()\n",
    "segment(folder, quality_control, participants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
